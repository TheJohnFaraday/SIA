# Show / Hide plots
plot = false

# [Optional] Seed for RNG. Comment it out for randomness, or set an integer for determinism
seed = 20241006
learning_rate = 0.01
beta = 0.4
train_proportion = 0.7
epoch=100
noise_val=0.3


[and]
input = [[-1,1],[1,-1],[-1,-1],[1,1]]
output = [-1,-1,-1,1]

[xor]
input = [[-1,1],[1,-1],[-1,-1],[1,1]]
output = [1,1,-1,-1]

[single_layer.linear_non_linear]
path = "datasets/TP3-ej2-conjunto.csv"
# Activation function: 'tanh' or 'logistic'
activation_function = "logistic"

[multi_layer]
# Choose one between 'online', 'minibatch' and 'batch'
training_style = 'batch'
# If 'minibatch' is chosen, a batch_size is needed
batch_size = 2
# Optimizer must be one of: 'gradient_descent', 'momentum', and 'adam'
optimizer = 'adam'
# Acceptable error value
acceptable_error_epsilon=0.0000001

[multi_layer.parity_discrimination]
path = "datasets/TP3-ej3-digitos.txt"
# Activation function: 'tanh' or 'logistic'
activation_function = "tanh"

[multi_layer.digit_discrimination]
# Activation function: 'tanh' or 'logistic'
activation_function = "tanh"

[multi_layer.mnist]
path="mnist.npz"

[multi_layer.momentum]
# Usually 0.8 or 0.9. Must be in range [0, 1]
alpha=0.8

[multi_layer.adam]
beta1=0.9
beta2=0.999
epsilon=1e-8
